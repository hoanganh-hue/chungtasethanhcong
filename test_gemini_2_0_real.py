#!/usr/bin/env python3
"""
Test script for Gemini 2.0 Flash with real API key
Test the complete integration with actual Google Gemini API
"""

import asyncio
import json
import sys
import os
from datetime import datetime
from typing import Dict, Any, List, Optional, AsyncGenerator
from dataclasses import dataclass
from enum import Enum

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

# Direct imports for testing
from src.ai.gemini_client import GeminiClient, GeminiConfig, GeminiMessage, GeminiModel

# Your API key
GEMINI_API_KEY = "AIzaSyAUnuPqbJfbcnIaTMjQvEXC4pqgoN3H3dU"

async def test_gemini_2_0_basic():
    """Test basic Gemini 2.0 Flash functionality."""
    print("ğŸ§ª Testing Gemini 2.0 Flash Basic Functionality...")
    
    try:
        # Create Gemini client with 2.0 Flash
        config = GeminiConfig(
            api_key=GEMINI_API_KEY,
            model=GeminiModel.GEMINI_2_0_FLASH.value,
            temperature=0.7,
            max_tokens=1024
        )
        
        client = GeminiClient(config)
        
        # Initialize client
        print("ğŸ”„ Initializing Gemini 2.0 Flash client...")
        if not await client.initialize():
            print("âŒ Failed to initialize Gemini client")
            return False
        
        print("âœ… Gemini 2.0 Flash client initialized successfully")
        
        # Test basic message
        print("ğŸ”„ Testing basic message...")
        message = GeminiMessage(
            role="user",
            parts=[{"text": "Hello! Please respond with 'Gemini 2.0 Flash is working!' in Vietnamese."}],
            timestamp=datetime.now()
        )
        
        response_chunks = []
        async for chunk in client.generate_content([message], stream=False):
            response_chunks.append(chunk)
        
        if response_chunks:
            response = "".join(response_chunks)
            print(f"âœ… Basic message response: {response}")
        else:
            print("âŒ No response received")
            return False
        
        # Test Vietnamese response
        print("ğŸ”„ Testing Vietnamese language...")
        vietnamese_message = GeminiMessage(
            role="user",
            parts=[{"text": "Xin chÃ o! Báº¡n cÃ³ thá»ƒ giÃºp tÃ´i táº¡o 100 CCCD cho tá»‰nh HÆ°ng YÃªn, giá»›i tÃ­nh ná»¯, nÄƒm sinh tá»« 1965 Ä‘áº¿n 1975 khÃ´ng?"}],
            timestamp=datetime.now()
        )
        
        response_chunks = []
        async for chunk in client.generate_content([vietnamese_message], stream=False):
            response_chunks.append(chunk)
        
        if response_chunks:
            response = "".join(response_chunks)
            print(f"âœ… Vietnamese response: {response[:200]}...")
        else:
            print("âŒ No Vietnamese response received")
            return False
        
        # Cleanup
        await client.close()
        print("âœ… Gemini 2.0 Flash basic test completed successfully")
        return True
        
    except Exception as e:
        print(f"âŒ Gemini 2.0 Flash basic test failed: {e}")
        return False

async def test_gemini_2_0_streaming():
    """Test Gemini 2.0 Flash streaming functionality."""
    print("\nğŸ§ª Testing Gemini 2.0 Flash Streaming...")
    
    try:
        # Create Gemini client
        config = GeminiConfig(
            api_key=GEMINI_API_KEY,
            model=GeminiModel.GEMINI_2_0_FLASH.value,
            temperature=0.7,
            max_tokens=1024
        )
        
        client = GeminiClient(config)
        await client.initialize()
        
        # Test streaming response
        print("ğŸ”„ Testing streaming response...")
        message = GeminiMessage(
            role="user",
            parts=[{"text": "HÃ£y giáº£i thÃ­ch cÃ¡ch AI hoáº¡t Ä‘á»™ng trong vÃ i tá»« ngáº¯n gá»n báº±ng tiáº¿ng Viá»‡t."}],
            timestamp=datetime.now()
        )
        
        print("ğŸ“¡ Streaming response:")
        chunk_count = 0
        async for chunk in client.generate_content([message], stream=True):
            print(f"   Chunk {chunk_count + 1}: {chunk}", end="", flush=True)
            chunk_count += 1
        
        print(f"\nâœ… Streaming completed: {chunk_count} chunks received")
        
        # Cleanup
        await client.close()
        print("âœ… Gemini 2.0 Flash streaming test completed successfully")
        return True
        
    except Exception as e:
        print(f"âŒ Gemini 2.0 Flash streaming test failed: {e}")
        return False

async def test_gemini_2_0_function_calling():
    """Test Gemini 2.0 Flash function calling."""
    print("\nğŸ§ª Testing Gemini 2.0 Flash Function Calling...")
    
    try:
        # Create Gemini client
        config = GeminiConfig(
            api_key=GEMINI_API_KEY,
            model=GeminiModel.GEMINI_2_0_FLASH.value,
            temperature=0.3,  # Lower temperature for function calling
            max_tokens=1024
        )
        
        client = GeminiClient(config)
        await client.initialize()
        
        # Define a test function
        def test_cccd_generation(province: str, gender: str, quantity: int, birth_year_range: str) -> str:
            """Test function for CCCD generation."""
            return f"Generated {quantity} CCCD for {province}, gender: {gender}, birth years: {birth_year_range}"
        
        # Register function
        from src.ai.gemini_client import OpenManusFunctions
        cccd_func = OpenManusFunctions.get_cccd_generation_function()
        client.register_function(cccd_func, test_cccd_generation)
        
        print("âœ… Function registered successfully")
        
        # Test function calling
        print("ğŸ”„ Testing function calling...")
        message = GeminiMessage(
            role="user",
            parts=[{"text": "Táº¡o 100 CCCD cho tá»‰nh HÆ°ng YÃªn, giá»›i tÃ­nh ná»¯, nÄƒm sinh tá»« 1965 Ä‘áº¿n 1975"}],
            timestamp=datetime.now()
        )
        
        response_chunks = []
        async for chunk in client.generate_content([message], stream=False):
            response_chunks.append(chunk)
        
        if response_chunks:
            response = "".join(response_chunks)
            print(f"âœ… Function calling response: {response}")
        else:
            print("âŒ No function calling response received")
            return False
        
        # Cleanup
        await client.close()
        print("âœ… Gemini 2.0 Flash function calling test completed successfully")
        return True
        
    except Exception as e:
        print(f"âŒ Gemini 2.0 Flash function calling test failed: {e}")
        return False

async def test_gemini_2_0_cccd_workflow():
    """Test complete CCCD workflow with Gemini 2.0 Flash."""
    print("\nğŸ§ª Testing CCCD Workflow with Gemini 2.0 Flash...")
    
    try:
        # Create Gemini client
        config = GeminiConfig(
            api_key=GEMINI_API_KEY,
            model=GeminiModel.GEMINI_2_0_FLASH.value,
            temperature=0.3,
            max_tokens=2048
        )
        
        client = GeminiClient(config)
        await client.initialize()
        
        # Register CCCD functions
        from src.ai.gemini_client import OpenManusFunctions
        
        def generate_cccd(province: str, gender: str, quantity: int, birth_year_range: str) -> str:
            return f"âœ… ÄÃ£ táº¡o {quantity} CCCD cho tá»‰nh {province}, giá»›i tÃ­nh {gender}, nÄƒm sinh {birth_year_range}"
        
        def check_cccd(cccd_number: str) -> str:
            return f"âœ… ÄÃ£ kiá»ƒm tra CCCD {cccd_number}: ThÃ´ng tin há»£p lá»‡"
        
        def lookup_tax(tax_code: str) -> str:
            return f"âœ… ÄÃ£ tra cá»©u mÃ£ sá»‘ thuáº¿ {tax_code}: ThÃ´ng tin Ä‘Ã£ Ä‘Æ°á»£c tÃ¬m tháº¥y"
        
        # Register functions
        client.register_function(OpenManusFunctions.get_cccd_generation_function(), generate_cccd)
        client.register_function(OpenManusFunctions.get_cccd_check_function(), check_cccd)
        client.register_function(OpenManusFunctions.get_tax_lookup_function(), lookup_tax)
        
        print("âœ… CCCD functions registered successfully")
        
        # Test workflow scenarios
        test_scenarios = [
            "Táº¡o 100 CCCD cho tá»‰nh HÆ°ng YÃªn, giá»›i tÃ­nh ná»¯, nÄƒm sinh tá»« 1965 Ä‘áº¿n 1975",
            "Kiá»ƒm tra CCCD 031089011929",
            "Tra cá»©u mÃ£ sá»‘ thuáº¿ 037178000015",
            "Táº¡o 50 CCCD cho tá»‰nh HÃ  Ná»™i, giá»›i tÃ­nh nam, nÄƒm sinh tá»« 1980 Ä‘áº¿n 1990"
        ]
        
        for i, scenario in enumerate(test_scenarios, 1):
            print(f"\nğŸ”„ Test scenario {i}: {scenario}")
            
            message = GeminiMessage(
                role="user",
                parts=[{"text": scenario}],
                timestamp=datetime.now()
            )
            
            response_chunks = []
            async for chunk in client.generate_content([message], stream=False):
                response_chunks.append(chunk)
            
            if response_chunks:
                response = "".join(response_chunks)
                print(f"âœ… Response: {response}")
            else:
                print("âŒ No response received")
        
        # Cleanup
        await client.close()
        print("\nâœ… CCCD workflow test completed successfully")
        return True
        
    except Exception as e:
        print(f"âŒ CCCD workflow test failed: {e}")
        return False

async def test_gemini_2_0_performance():
    """Test Gemini 2.0 Flash performance."""
    print("\nğŸ§ª Testing Gemini 2.0 Flash Performance...")
    
    try:
        # Create Gemini client
        config = GeminiConfig(
            api_key=GEMINI_API_KEY,
            model=GeminiModel.GEMINI_2_0_FLASH.value,
            temperature=0.7,
            max_tokens=512
        )
        
        client = GeminiClient(config)
        await client.initialize()
        
        # Test multiple requests
        print("ğŸ”„ Testing multiple concurrent requests...")
        
        async def single_request(request_id: int):
            message = GeminiMessage(
                role="user",
                parts=[{"text": f"Request {request_id}: HÃ£y tráº£ lá»i ngáº¯n gá»n vá» AI"}],
                timestamp=datetime.now()
            )
            
            start_time = datetime.now()
            response_chunks = []
            async for chunk in client.generate_content([message], stream=False):
                response_chunks.append(chunk)
            end_time = datetime.now()
            
            response_time = (end_time - start_time).total_seconds()
            return request_id, response_time, len("".join(response_chunks))
        
        # Run 5 concurrent requests
        tasks = [single_request(i) for i in range(1, 6)]
        results = await asyncio.gather(*tasks)
        
        print("ğŸ“Š Performance Results:")
        total_time = 0
        total_chars = 0
        
        for request_id, response_time, char_count in results:
            print(f"   Request {request_id}: {response_time:.2f}s, {char_count} chars")
            total_time += response_time
            total_chars += char_count
        
        avg_time = total_time / len(results)
        avg_chars = total_chars / len(results)
        
        print(f"âœ… Average response time: {avg_time:.2f}s")
        print(f"âœ… Average response length: {avg_chars:.0f} characters")
        print(f"âœ… Total requests: {len(results)}")
        
        # Cleanup
        await client.close()
        print("âœ… Performance test completed successfully")
        return True
        
    except Exception as e:
        print(f"âŒ Performance test failed: {e}")
        return False

async def main():
    """Run all Gemini 2.0 Flash tests."""
    print("ğŸš€ Starting Gemini 2.0 Flash Integration Tests")
    print("=" * 60)
    print(f"ğŸ”‘ API Key: {GEMINI_API_KEY[:10]}...")
    print(f"ğŸ¤– Model: Gemini 2.0 Flash")
    print("=" * 60)
    
    test_results = []
    
    # Run all tests
    test_results.append(await test_gemini_2_0_basic())
    test_results.append(await test_gemini_2_0_streaming())
    test_results.append(await test_gemini_2_0_function_calling())
    test_results.append(await test_gemini_2_0_cccd_workflow())
    test_results.append(await test_gemini_2_0_performance())
    
    # Summary
    print("\n" + "=" * 60)
    print("ğŸ‰ Gemini 2.0 Flash Integration Tests Completed!")
    
    passed_tests = sum(test_results)
    total_tests = len(test_results)
    
    print(f"\nğŸ“Š Test Results: {passed_tests}/{total_tests} tests passed")
    
    if passed_tests == total_tests:
        print("ğŸ‰ All tests passed! Gemini 2.0 Flash integration is working perfectly!")
    else:
        print("âš ï¸  Some tests failed. Please check the error messages above.")
    
    print("\nğŸ”§ Features Tested:")
    print("âœ… Basic message generation")
    print("âœ… Vietnamese language support")
    print("âœ… Streaming responses")
    print("âœ… Function calling")
    print("âœ… CCCD workflow integration")
    print("âœ… Performance testing")
    
    print("\nğŸš€ Next Steps:")
    print("1. Integrate with Unified Gemini Agent")
    print("2. Test with real CCCD generation")
    print("3. Deploy to production")
    print("4. Monitor performance and usage")

if __name__ == "__main__":
    asyncio.run(main())